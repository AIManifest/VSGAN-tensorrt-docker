{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-VSGAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab-VSGAN\n",
        "\n",
        "My repo: [styler00dollar/VSGAN-tensorrt-docker](https://github.com/styler00dollar/VSGAN-tensorrt-docker/)"
      ],
      "metadata": {
        "id": "hpqbFInxrYdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am not sure why, but the compact model does not seem to work.\n",
        "\n",
        "```\n",
        "[lrc @ 0x55c14252c000] Format lrc detected only with low score of 5, misdetection possible!\n",
        "```\n",
        "The other stuff seems to work."
      ],
      "metadata": {
        "id": "eAc-faj-eW-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "dfWp19tKePiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "50YNOoUCgcbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check python version, for me its currently 3.7.12\n",
        "!python --version"
      ],
      "metadata": {
        "id": "hjfnge1eeR4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4LVR-piSdQRT"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You need to get 2 files. Currently, the cuda version inside Colab is 11.1, that's why you need to get:\n",
        "```\n",
        "nv-tensorrt-repo-ubuntu1804-cuda11.4-trt8.2.3.0-ga-20220113_1-1_amd64.deb\n",
        "\n",
        "(TensorRT 8.2 GA Update 2 for Ubuntu 18.04 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4 and 11.5 DEB local repo Package)\n",
        "\n",
        "and\n",
        "\n",
        "TensorRT-8.2.3.0.Linux.x86_64-gnu.cuda-11.4.cudnn8.2.tar.gz/python/tensorrt-8.2.3.0-cp37-none-linux_x86_64.whl\n",
        "\n",
        "(TensorRT 8.2 GA Update 2 for Linux x86_64 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4 and 11.5 TAR Package)\n",
        "\n",
        "```\n",
        "You can download these files [here](https://developer.nvidia.com/nvidia-tensorrt-download). Warning: You need an account (which can be created for free). Put them into `gdrive/TensorRT`."
      ],
      "metadata": {
        "id": "xF70uc_kfReq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install\n",
        "import os\n",
        "os.environ[\"os1\"]=\"ubuntu1804\"\n",
        "os.environ[\"tag\"]= \"cuda11.4-trt8.2.3.0-ga-20220113\" #@param\n",
        "os.environ[\"version\"]= \"8.2.3-1+cuda11.4\" #@param\n",
        "data_path = '/content/drive/MyDrive/TensorRT/' #@param\n",
        "os.chdir(data_path)\n",
        "!sudo dpkg -i nv-tensorrt-repo-${os1}-${tag}_1-1_amd64.deb\n",
        "!sudo apt-key add /var/nv-tensorrt-repo-${tag}/7fa2af80.pub\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install libnvinfer8=${version} libnvonnxparsers8=${version} libnvparsers8=${version} libnvinfer-plugin8=${version} libnvinfer-dev=${version} libnvonnxparsers-dev=${version} libnvparsers-dev=${version} libnvinfer-plugin-dev=${version} python3-libnvinfer=${version}\n",
        "!sudo apt-mark hold libnvinfer8 libnvonnxparsers8 libnvparsers8 libnvinfer-plugin8 libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev python3-libnvinfer\n",
        "!sudo apt-get install tensorrt=8.2.3.0-1+cuda11.4\n",
        "!sudo apt-get install python3-libnvinfer-dev=${version}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KC8tnFafdTRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Runtime -> Restart runtime`"
      ],
      "metadata": {
        "id": "02VtRLyCkdUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the whl with the matching python version\n",
        "!pip install \"/content/drive/MyDrive/TensorRT/tensorrt-8.2.3.0-cp37-none-linux_x86_64.whl\""
      ],
      "metadata": {
        "id": "_sL3tvJzdUxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Runtime -> Restart runtime`"
      ],
      "metadata": {
        "id": "aPtmePtLkmZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install everything. Avoid compiling mmcv if you can, since the total install time will be long."
      ],
      "metadata": {
        "id": "50Ap6W6d3QdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install (be patient, ~12min)\n",
        "%cd /content/\n",
        "!sudo rm -rf /workspace\n",
        "!mkdir /workspace/tensorrt\n",
        "%cd /workspace/tensorrt\n",
        "\n",
        "# installing vapoursynth\n",
        "!apt install ffmpeg autoconf libtool yasm python3.9 python3.9-venv python3.9-dev ffmsindex libffms2-4 libffms2-dev -y\n",
        "!apt --fix-broken install\n",
        "!git clone https://github.com/sekrit-twc/zimg.git && cd zimg && ./autogen.sh && ./configure && make -j4 && make install && cd .. && rm -rf zimg\n",
        "!pip install Cython -U --force-reinstall\n",
        "!wget https://github.com/vapoursynth/vapoursynth/archive/refs/tags/R57.zip -P /workspace/tensorrt\n",
        "%cd /workspace/tensorrt/\n",
        "!7z x /workspace/tensorrt/R57.zip\n",
        "%cd /workspace/tensorrt/vapoursynth-R57\n",
        "!./autogen.sh && ./configure && make && make install && cd .. && ldconfig\n",
        "!ln -s /usr/local/lib/python3.7/site-packages/vapoursynth.so /usr/lib/python3.7/lib-dynload/vapoursynth.so\n",
        "!pip install vapoursynth\n",
        "\n",
        "# cupy / pycuda\n",
        "!curl https://colab.chainer.org/install | sh -\n",
        "!pip install pycuda\n",
        "\n",
        "# pytorch tensorrt\n",
        "!pip install https://github.com/NVIDIA/Torch-TensorRT/releases/download/v1.0.0/torch_tensorrt-1.0.0-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# onnx\n",
        "!pip install onnx onnxruntime onnxruntime-gpu\n",
        "\n",
        "# installing onnx tensorrt with a workaround, error with import otherwise\n",
        "%cd /workspace/tensorrt\n",
        "!git clone https://github.com/onnx/onnx-tensorrt\n",
        "%cd onnx-tensorrt\n",
        "!python3 setup.py install\n",
        "\n",
        "%cd /workspace\n",
        "# downloading models\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.3.0/RealESRGANv2-animevideo-xsx2.pth\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.3.0/RealESRGANv2-animevideo-xsx4.pth\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
        "# fatal anime\n",
        "!wget https://de-next.owncube.com/index.php/s/x99pKzS7TNaErrC/download -O 4x_fatal_Anime_500000_G.pth\n",
        "# rvp1\n",
        "!pip install gdown && gdown --id 1IJe6WLvT43iwl-3J6ectgnjas5mjnQ51\n",
        "# sepconv\n",
        "!wget http://content.sniklaus.com/resepconv/network-paper.pytorch -O sepconv.pth\n",
        "# EGVSR\n",
        "!wget https://github.com/Thmen/EGVSR/raw/master/pretrained_models/EGVSR_iter420000.pth\n",
        "# rife4 (fixed rife4.0 model)\n",
        "!gdown --id 1UzCbpjxWJsfiDjoc7wuzq3K0RCf5Oxr3\n",
        "# RealBasicVSR_x4\n",
        "!gdown --id 1OYR1J2GXE90Zu2gVU5xc0t0P_UmKH7ID\n",
        "\n",
        "# optional, rvp uses it to convert colorspace\n",
        "!pip install kornia\n",
        "# image read/write for image inference\n",
        "!pip install opencv-python\n",
        "\n",
        "# vs plugings from others\n",
        "# https://github.com/HolyWu/vs-swinir\n",
        "!pip install --upgrade vsswinir && python -m vsswinir\n",
        "\n",
        "# pytorch hotfix\n",
        "!pip uninstall torch -y\n",
        "!pip uninstall torch -y\n",
        "!pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "\n",
        "# onnx gpu hotfix\n",
        "!pip install onnxruntime-gpu --force-reinstall -U\n",
        "\n",
        "# jpg turbo\n",
        "!sudo apt-get install -y libturbojpeg \n",
        "!pip install PyTurboJPEG"
      ],
      "metadata": {
        "id": "tgqMOgQvdaad",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (optional) compile mmcv (basicvsrpp/RealBasicVSR)\n",
        "#@markdown Compiling mmcv takes a while, only do this if you need it\n",
        "# https://github.com/HolyWu/vs-basicvsrpp\n",
        "!pip install --upgrade vsbasicvsrpp && python -m vsbasicvsrpp\n",
        "# dependencies for RealBasicVSR_x4\n",
        "# mmedit\n",
        "!git clone https://github.com/open-mmlab/mmediting.git && cd mmediting && pip install -v -e .\n",
        "# RealBasicVSR_x4 will download this\n",
        "!wget \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" -P /root/.cache/torch/hub/checkpoints/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dqPcNbBww6uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Runtime -> Restart runtime`"
      ],
      "metadata": {
        "id": "bTuK32lZyMFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies are installed now."
      ],
      "metadata": {
        "id": "ONt5BNaLoMho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /workspace/tensorrt\n",
        "!git clone https://github.com/styler00dollar/VSGAN-tensorrt-docker\n",
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker"
      ],
      "metadata": {
        "id": "4OUgqwohoPSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title inference.py\n",
        "%%writefile /workspace/tensorrt/VSGAN-tensorrt-docker/inference.py\n",
        "import sys\n",
        "sys.path.append('/workspace/tensorrt/VSGAN-tensorrt-docker/')\n",
        "import vapoursynth as vs\n",
        "from src.esrgan import ESRGAN_inference # esrgan and realesrgan\n",
        "from src.SRVGGNetCompact import SRVGGNetCompactRealESRGAN # realesrgan anime video\n",
        "from src.vfi_model import video_model # any vfi model, in this case rvp1 as demonstration\n",
        "from src.sepconv_enhanced import sepconv_model # uses cupy, no tensorrt\n",
        "from src.rife import RIFE # tensorrt not possible\n",
        "from vsswinir import SwinIR # https://github.com/HolyWu/vs-swinir # currently not tensorrt, didn't try\n",
        "from src.egvsr import egvsr_model # currently not tensorrt\n",
        "#from vsbasicvsrpp import BasicVSRPP\n",
        "#from src.realbasicvsr import realbasicvsr_model\n",
        "\n",
        "core = vs.core\n",
        "vs_api_below4 = vs.__api_version__.api_major < 4\n",
        "core = vs.core\n",
        "core.num_threads = 16 # can influence ram usage\n",
        "# only needed if you are inside docker\n",
        "core.std.LoadPlugin(path='/usr/lib/x86_64-linux-gnu/libffms2.so')\n",
        "\n",
        "# cfr video\n",
        "clip = core.ffms2.Source(source='480.mkv')\n",
        "# vfr video (untested)\n",
        "#clip = core.ffms2.Source(source='input.mkv', fpsnum = 24000, fpsden = 1001)\n",
        "###############################################\n",
        "# COLORSPACE\n",
        "###############################################\n",
        "# convert colorspace\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.RGBS, matrix_in_s='709')\n",
        "# convert colorspace + resizing\n",
        "#clip = vs.core.resize.Bicubic(clip, width=848, height=480, format=vs.RGBS, matrix_in_s='709')\n",
        "\n",
        "###############################################\n",
        "\n",
        "# these demos work out of the box because docker also downloads the needed models, if you want other models, just add them\n",
        "# you can combine everything however you want\n",
        "\n",
        "###############################################\n",
        "# MODELS (CUDA)\n",
        "###############################################\n",
        "# sepconv\n",
        "#clip = sepconv_model(clip)\n",
        "# RIFE4\n",
        "clip = RIFE(clip, multi = 2, scale = 1.0, fp16 = True, fastmode = False, ensemble = True)\n",
        "# VFI example for jit models\n",
        "#clip = video_model(clip, fp16=False, model_path=\"/workspace/rvpV1_105661_G.pt\")\n",
        "# SwinIR\n",
        "#clip = SwinIR(clip, task=\"lightweight_sr\", scale=2)\n",
        "# ESRGAN / RealESRGAN\n",
        "#clip = ESRGAN_inference(clip=clip, model_path=\"/workspace/4x_fatal_Anime_500000_G.pth\", tile_x=400, tile_y=400, tile_pad=10, fp16=False)\n",
        "#clip = ESRGAN_inference(clip=clip, model_path=\"/workspace/RealESRGAN_x4plus_anime_6B.pth\", tile_x=480, tile_y=480, tile_pad=16, fp16=False)\n",
        "# RealESRGAN Anime Video example\n",
        "# backends: tenssorrt, cuda, onnx, quantized_onnx\n",
        "#clip = SRVGGNetCompactRealESRGAN(clip, scale=2, fp16=True, backend = \"cuda\")\n",
        "# EGVSR\n",
        "#clip = egvsr_model(clip, interval=15)\n",
        "# BasicVSR++\n",
        "# 0 = REDS, 1 = Vimeo-90K (BI), 2 = Vimeo-90K (BD), 3 = NTIRE 2021 - Track 1, 4 = NTIRE 2021 - Track 2, 5 = NTIRE 2021 - Track 3\n",
        "#clip = BasicVSRPP(clip, model = 1, interval = 30, tile_x = 0, tile_y = 0, tile_pad = 16, device_type = 'cuda', device_index = 0, fp16 = False, cpu_cache = False)\n",
        "# RealBasicVSR\n",
        "#clip = realbasicvsr_model(clip, interval=15, fp16=True)\n",
        "\n",
        "###############################################\n",
        "# [NOT IN DOCKER] MODELS (NCNN)\n",
        "# Only recommended for AMD GPUS, further instructions in README\n",
        "###############################################\n",
        "#from src.SRVGGNetCompact_ncnn import SRVGGNetCompactRealESRGAN_ncnn\n",
        "\n",
        "# Rife ncnn\n",
        "# 0 = rife-v3.1, 1 = rife-v3.0, 2 = rife-v2.4, 3 = rife-v2, 4 = rife-anime\n",
        "#clip = core.rife.RIFE(clip, model=0, gpu_id=0, gpu_thread=2, tta=False, uhd=False, sc=False, list_gpu=False)\n",
        "# RealESRGAN example\n",
        "#clip = SRVGGNetCompactRealESRGAN_ncnn(clip, gpuid=0, model=\"models-DF2K\", tta_mode=False, scale = 2, tilesize=0, param_path = None, bin_path = None)\n",
        "# Waifu2x\n",
        "# 0 = upconv_7_anime_style_art_rgb, 1 = upconv_7_photo, 2 = cunet (For 2D artwork. Slow, but better quality.)\n",
        "#clip = core.w2xnvk.Waifu2x(clip, noise=0, scale=2, model=0, tile_size=0, gpu_id=0, gpu_thread=0, precision=16)\n",
        "\n",
        "###############################################\n",
        "# OUTPUT\n",
        "###############################################\n",
        "clip = vs.core.resize.Bicubic(clip, format=vs.YUV420P8, matrix_s=\"709\")\n",
        "clip.set_output()\n"
      ],
      "metadata": {
        "id": "2jdfZgcfnsky",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /workspace/tensorrt/VSGAN-tensorrt-docker/\n",
        "!vspipe -c y4m inference.py - | ffmpeg -i pipe: /workspace/tensorrt/VSGAN-tensorrt-docker/example.mkv"
      ],
      "metadata": {
        "id": "QOker8lwgE2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}